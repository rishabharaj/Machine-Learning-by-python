# Introduction to Deep Learning Frameworks

## Overview

Deep learning frameworks provide tools and abstractions to build, train, and deploy neural networks. The two most popular frameworks are TensorFlow and PyTorch.

## TensorFlow

### What is TensorFlow?
- Developed by Google
- Open-source framework
- High-level and low-level APIs
- Strong production capabilities

### Key Features
- TensorFlow 2.x with eager execution
- Keras API integration
- Extensive ecosystem
- Cross-platform support

### Installation

#### Using pip
```bash
# Install TensorFlow
pip install tensorflow

# Install GPU version (if you have CUDA-compatible GPU)
pip install tensorflow-gpu
```

#### Using conda
```bash
# Create new environment
conda create -n tf_env python=3.8

# Activate environment
conda activate tf_env

# Install TensorFlow
conda install tensorflow
```

### Basic Usage
```python
import tensorflow as tf

# Check version
print(tf.__version__)

# Verify GPU availability
print("GPU Available:", tf.config.list_physical_devices('GPU'))
```

## PyTorch

### What is PyTorch?
- Developed by Facebook
- Dynamic computation graphs
- Pythonic approach
- Strong research focus

### Key Features
- Dynamic computation graphs
- Native Python integration
- Strong GPU acceleration
- Active research community

### Installation

#### Using pip
```bash
# Install PyTorch (CPU version)
pip install torch torchvision torchaudio

# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
```

#### Using conda
```bash
# Create new environment
conda create -n torch_env python=3.8

# Activate environment
conda activate torch_env

# Install PyTorch
conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch
```

### Basic Usage
```python
import torch

# Check version
print(torch.__version__)

# Verify GPU availability
print("GPU Available:", torch.cuda.is_available())
```

## Framework Comparison

### TensorFlow vs PyTorch

#### TensorFlow Advantages
- Better production deployment
- More mature ecosystem
- Strong mobile support
- Better visualization tools

#### PyTorch Advantages
- More intuitive API
- Better debugging
- Dynamic computation graphs
- Strong research community

## Choosing a Framework

### When to Use TensorFlow
- Production deployment
- Mobile applications
- Large-scale systems
- Enterprise solutions

### When to Use PyTorch
- Research projects
- Rapid prototyping
- Dynamic architectures
- Academic work

## Getting Started with TensorFlow

### Basic Neural Network Example
```python
import tensorflow as tf
from tensorflow import keras

# Create a simple model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=5)
```

## Getting Started with PyTorch

### Basic Neural Network Example
```python
import torch
import torch.nn as nn

# Define a simple model
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.layer1 = nn.Linear(784, 64)
        self.layer2 = nn.Linear(64, 10)
    
    def forward(self, x):
        x = torch.relu(self.layer1(x))
        x = self.layer2(x)
        return x

# Create model instance
model = SimpleNN()

# Define loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters())

# Training loop
for epoch in range(5):
    # Forward pass
    outputs = model(inputs)
    loss = criterion(outputs, labels)
    
    # Backward pass
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

## Next Steps

1. Install your chosen framework
2. Run the basic examples
3. Move on to building your first neural network
4. Experiment with different architectures 